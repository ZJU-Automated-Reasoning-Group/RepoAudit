#!/usr/bin/env python3
"""
LLM x æ¼æ´æŒ–æ˜ - å†…å­˜å®‰å…¨æ¼æ´é™æ€å®¡è®¡ç³»ç»Ÿ
å•ä¸€æ¼æ´ç±»å‹æ£€æµ‹ï¼Œå¤šæ¨¡å‹ååŒåˆ¤æ–­
"""

import sys
import os
from pathlib import Path

# Add src directory to Python path
BASE_PATH = Path(__file__).resolve().parents[2]
sys.path.insert(0, str(BASE_PATH / "src"))

import json
import time
from dataclasses import dataclass
from typing import List, Dict, Optional
from enum import Enum
from concurrent.futures import ThreadPoolExecutor, as_completed

from llmtool.LLM_tool import LLMTool, LLMToolInput, LLMToolOutput
from ui.logger import Logger


class VulnType(Enum):
    NPD = "Null Pointer Dereference"
    UAF = "Use-After-Free"
    BOF = "Buffer Overflow"
    ML = "Memory Leak"


class Severity(Enum):
    CRITICAL = "ä¸¥é‡"
    HIGH = "é«˜å±"
    MEDIUM = "ä¸­å±"
    LOW = "ä½å±"


@dataclass
class Finding:
    vuln_type: VulnType
    severity: Severity
    description: str
    line_range: str
    confidence: float
    agent_id: str


class MemoryAuditInput(LLMToolInput):
    def __init__(self, code: str, bug_type: VulnType, language: str = "C"):
        self.code = code
        self.bug_type = bug_type
        self.language = language
    
    def __hash__(self):
        return hash((self.code, self.bug_type.name, self.language))


class MemoryAuditOutput(LLMToolOutput):
    def __init__(self, findings: List[Finding]):
        self.findings = findings


class VulnerabilityAnalyzer(LLMTool):
    """é€šç”¨æ¼æ´åˆ†æå·¥å…·"""
    def __init__(self, model_name: str, agent_id: str, temperature: float, language: str, max_query_num: int, logger: Logger):
        super().__init__(model_name, temperature, language, max_query_num, logger)
        self.agent_id = agent_id
    
    def _get_prompt(self, input: MemoryAuditInput) -> str:
        bug_descriptions = {
            VulnType.NPD: "ç©ºæŒ‡é’ˆè§£å¼•ç”¨ - è®¿é—®NULLæŒ‡é’ˆ",
            VulnType.UAF: "é‡Šæ”¾åä½¿ç”¨ - ä½¿ç”¨å·²é‡Šæ”¾çš„å†…å­˜",
            VulnType.BOF: "ç¼“å†²åŒºæº¢å‡º - å†™å…¥è¶…å‡ºç¼“å†²åŒºè¾¹ç•Œ",
            VulnType.ML: "å†…å­˜æ³„æ¼ - åˆ†é…çš„å†…å­˜æœªé‡Šæ”¾"
        }
        
        return f"""ä½ æ˜¯å®‰å…¨ä¸“å®¶ï¼Œéœ€è¦æ£€æŸ¥{input.language}ä»£ç ä¸­çš„{bug_descriptions[input.bug_type]}æ¼æ´ã€‚

ä»£ç ï¼š
```{input.language}
{input.code}
```

è¯·ä»”ç»†åˆ†æä»£ç ï¼Œåªå…³æ³¨{input.bug_type.value}ç±»å‹çš„æ¼æ´ã€‚

è¿”å›JSONæ ¼å¼ï¼š
{{
    "findings": [
        {{
            "severity": "CRITICAL|HIGH|MEDIUM|LOW",
            "description": "è¯¦ç»†æè¿°å‘ç°çš„é—®é¢˜",
            "line_range": "L1-L3",
            "confidence": 0.85
        }}
    ]
}}

å¦‚æœæ²¡æœ‰å‘ç°é—®é¢˜ï¼Œè¿”å›ç©ºæ•°ç»„ã€‚åªè¿”å›JSONï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚"""

    def _parse_response(self, response: str, input: MemoryAuditInput = None) -> MemoryAuditOutput:
        try:
            # Clean the response to extract JSON
            response = response.strip()
            
            # Remove code block markers if present
            if "```json" in response:
                start = response.find("```json") + 7
                end = response.find("```", start)
                if end != -1:
                    response = response[start:end]
            elif "```" in response:
                start = response.find("```") + 3
                end = response.find("```", start)
                if end != -1:
                    response = response[start:end]
            
            response = response.strip()
            
            # Skip empty responses
            if not response:
                return MemoryAuditOutput([])
            
            # Parse JSON
            data = json.loads(response)
            findings = []
            
            for item in data.get("findings", []):
                finding = Finding(
                    vuln_type=input.bug_type,
                    severity=Severity[item["severity"]],
                    description=item["description"],
                    line_range=item["line_range"],
                    confidence=item["confidence"],
                    agent_id=self.agent_id
                )
                findings.append(finding)
            return MemoryAuditOutput(findings)
        except Exception as e:
            self.logger.print_log(f"Error parsing {self.agent_id} response: {e}")
            self.logger.print_log(f"Raw response: {response}")
            return MemoryAuditOutput([])


class MemoryAuditor:
    def __init__(self, bug_type: VulnType, language: str = "C", temperature: float = 0.0):
        self.bug_type = bug_type
        self.language = language
        self.temperature = temperature
        
        # Initialize logger
        log_dir = f"{BASE_PATH}/log/swarm_audit/{bug_type.name}/{time.strftime('%Y-%m-%d-%H-%M-%S', time.localtime())}"
        os.makedirs(log_dir, exist_ok=True)
        self.logger = Logger(f"{log_dir}/audit.log")
        
        # Initialize multiple models for the same bug type
        self.agents = [
            ("glm-4-flash", "å®‰å…¨ä¸“å®¶"),
            ("glm-4-flash", "é™æ€åˆ†æä¸“å®¶"),
            ("glm-4-flash", "èµ„æ·±ç¨‹åºå‘˜")
        ]
    
    def judge(self, all_findings: List[Finding]) -> List[Finding]:
        """ç»¼åˆåˆ¤æ–­ - è‡³å°‘2ä¸ªæ¨¡å‹åŒæ„æ‰ç¡®è®¤"""
        if len(all_findings) < 2:
            return []
        
        # æŒ‰ä½ç½®åˆ†ç»„
        grouped = {}
        for f in all_findings:
            key = f.line_range
            if key not in grouped:
                grouped[key] = []
            grouped[key].append(f)
        
        final_findings = []
        for line_range, findings in grouped.items():
            if len(findings) >= 2:  # è‡³å°‘2ä¸ªæ¨¡å‹æ£€æµ‹åˆ°
                avg_confidence = sum(f.confidence for f in findings) / len(findings)
                max_severity = max(findings, key=lambda x: list(Severity).index(x.severity)).severity
                
                final_findings.append(Finding(
                    vuln_type=self.bug_type,
                    severity=max_severity,
                    description=f"å¤šæ¨¡å‹ç¡®è®¤ï¼š{findings[0].description}",
                    line_range=line_range,
                    confidence=min(0.99, avg_confidence + 0.1),
                    agent_id="Judge"
                ))
        
        return final_findings
    
    def analyze(self, code: str) -> Dict:
        """åˆ†æä»£ç """
        self.logger.print_console(f"ğŸ” å¼€å§‹{self.bug_type.value}æ£€æµ‹...\n")
        
        audit_input = MemoryAuditInput(code, self.bug_type, self.language)
        all_findings = []
        
        # å¹¶è¡Œè°ƒç”¨å¤šä¸ªæ¨¡å‹
        with ThreadPoolExecutor(max_workers=len(self.agents)) as executor:
            futures = {}
            for model_name, agent_name in self.agents:
                analyzer = VulnerabilityAnalyzer(
                    model_name, agent_name, self.temperature, 
                    self.language, 5, self.logger
                )
                futures[executor.submit(analyzer.invoke, audit_input)] = agent_name
            
            for future in as_completed(futures):
                agent_name = futures[future]
                try:
                    output = future.result()
                    if output and output.findings:
                        all_findings.extend(output.findings)
                        self.logger.print_console(f"âœ… {agent_name} å‘ç°{len(output.findings)}ä¸ªé—®é¢˜")
                    else:
                        self.logger.print_console(f"âœ… {agent_name} æœªå‘ç°é—®é¢˜")
                except Exception as e:
                    self.logger.print_log(f"Error in {agent_name}: {e}")
                    self.logger.print_console(f"âŒ {agent_name} æ‰§è¡Œå¤±è´¥")
        
        # ç»¼åˆåˆ¤æ–­
        final_findings = self.judge(all_findings)
        
        return {
            "bug_type": self.bug_type.value,
            "total_findings": len(all_findings),
            "confirmed_findings": final_findings
        }

def main():
    # ç¤ºä¾‹ï¼šæ£€æµ‹UAFæ¼æ´
    code = """
    void example() {
        char *ptr = malloc(100);
        *ptr = 'A';
        free(ptr);
        *ptr = 'B';  // UAF here
    }
    """
    
    auditor = MemoryAuditor(VulnType.UAF)
    report = auditor.analyze(code)
    
    print(f"\nğŸ“Š {report['bug_type']}æ£€æµ‹å®Œæˆ")
    print(f"ğŸ“‹ å‘ç°{report['total_findings']}ä¸ªåˆæ­¥é—®é¢˜ï¼Œç¡®è®¤{len(report['confirmed_findings'])}ä¸ª\n")
    
    for f in report['confirmed_findings']:
        print(f"[{f.severity.value}] {f.description}")
        print(f"  ä½ç½®: {f.line_range}, ç½®ä¿¡åº¦: {f.confidence:.1%}\n")

if __name__ == "__main__":
    main()
